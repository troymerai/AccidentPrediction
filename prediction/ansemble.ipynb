{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train_org = pd.read_csv('train.csv') \n",
    "test_org = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns of train_df : Index(['ID', '요일', '기상상태', '시군구', '도로형태', '노면상태', '사고유형', '사고유형 - 세부분류',\\n       '법규위반', '가해운전자 차종', '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종',\\n       '피해운전자 성별', '피해운전자 연령', '피해운전자 상해정도', '사망자수', '중상자수', '경상자수', '부상자수',\\n       'ECLO', '연', '월', '일', '시간'],\\n      dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"columns of test_df : Index(['ID', '요일', '기상상태', '시군구', '도로형태', '노면상태', '사고유형', '연', '월', '일', '시간'], dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = train_org.copy()\n",
    "test_df = test_org.copy()\n",
    "\n",
    "time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})' \n",
    "\n",
    "train_df[['연', '월', '일', '시간']] = train_org['사고일시'].str.extract(time_pattern)\n",
    "train_df[['연', '월', '일', '시간']] = train_df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다 \n",
    "train_df = train_df.drop(columns=['사고일시']) # 정보 추출이 완료된 '사고일시' 컬럼은 제거합니다 \n",
    "\n",
    "# 해당 과정을 test_x에 대해서도 반복해줍니다 \n",
    "test_df[['연', '월', '일', '시간']] = test_org['사고일시'].str.extract(time_pattern)\n",
    "test_df[['연', '월', '일', '시간']] = test_df[['연', '월', '일', '시간']].apply(pd.to_numeric)\n",
    "test_df = test_df.drop(columns=['사고일시'])\n",
    "\n",
    "display(f\"columns of train_df : {train_df.columns}\")\n",
    "display(f\"columns of test_df : {test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns of train_df : Index(['ID', '요일', '기상상태', '도로형태', '노면상태', '사고유형', '사고유형 - 세부분류', '법규위반',\\n       '가해운전자 차종', '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종',\\n       '피해운전자 성별', '피해운전자 연령', '피해운전자 상해정도', '사망자수', '중상자수', '경상자수', '부상자수',\\n       'ECLO', '연', '월', '일', '시간', '도시', '구', '동'],\\n      dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"columns of test_df : Index(['ID', '요일', '기상상태', '도로형태', '노면상태', '사고유형', '연', '월', '일', '시간', '도시',\\n       '구', '동'],\\n      dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
    "\n",
    "train_df[['도시', '구', '동']] = train_org['시군구'].str.extract(location_pattern)\n",
    "train_df = train_df.drop(columns=['시군구'])\n",
    "\n",
    "test_df[['도시', '구', '동']] = test_org['시군구'].str.extract(location_pattern)\n",
    "test_df = test_df.drop(columns=['시군구'])\n",
    "\n",
    "display(f\"columns of train_df : {train_df.columns}\")\n",
    "display(f\"columns of test_df : {test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns of train_df : Index(['ID', '요일', '기상상태', '노면상태', '사고유형', '사고유형 - 세부분류', '법규위반', '가해운전자 차종',\\n       '가해운전자 성별', '가해운전자 연령', '가해운전자 상해정도', '피해운전자 차종', '피해운전자 성별',\\n       '피해운전자 연령', '피해운전자 상해정도', '사망자수', '중상자수', '경상자수', '부상자수', 'ECLO', '연',\\n       '월', '일', '시간', '도시', '구', '동', '도로형태1', '도로형태2'],\\n      dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"columns of test_df : Index(['ID', '요일', '기상상태', '노면상태', '사고유형', '연', '월', '일', '시간', '도시', '구', '동',\\n       '도로형태1', '도로형태2'],\\n      dtype='object')\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "road_pattern = r'(.+) - (.+)'\n",
    "\n",
    "train_df[['도로형태1', '도로형태2']] = train_org['도로형태'].str.extract(road_pattern)\n",
    "train_df = train_df.drop(columns=['도로형태'])\n",
    "\n",
    "test_df[['도로형태1', '도로형태2']] = test_org['도로형태'].str.extract(road_pattern)\n",
    "test_df = test_df.drop(columns=['도로형태'])\n",
    "\n",
    "display(f\"columns of train_df : {train_df.columns}\")\n",
    "display(f\"columns of test_df : {test_df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df.drop(columns=['ID']).copy()\n",
    "train_x = train_df[test_x.columns].copy()\n",
    "train_y = train_df['ECLO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['요일', '기상상태', '노면상태', '사고유형', '도시', '구', '동', '도로형태1', '도로형태2']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_features = list(train_x.dtypes[train_x.dtypes == \"object\"].index)\n",
    "# 추출된 문자열 변수 확인\n",
    "display(categorical_features)\n",
    "\n",
    "for i in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    le=le.fit(train_x[i]) \n",
    "    train_x[i]=le.transform(train_x[i])\n",
    "    \n",
    "    for case in np.unique(test_x[i]):\n",
    "        if case not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, case) \n",
    "    test_x[i]=le.transform(test_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231116_153053/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 3600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231116_153053/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.15\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Mon Apr 24 20:53:44 PDT 2023; root:xnu-8796.121.2~5/RELEASE_ARM64_T8103\n",
      "Disk Space Avail:   30.06 GB / 245.11 GB (12.3%)\n",
      "Train Data Rows:    39609\n",
      "Train Data Columns: 13\n",
      "Label Column: ECLO\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 46) unique label values:  [5, 3, 6, 18, 9, 8, 15, 2, 1, 7]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 26 out of 46 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9988386477820698\n",
      "Train Data Class Count: 26\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1186.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.11 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['도시']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 12 | ['요일', '기상상태', '노면상태', '사고유형', '연', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 12 | ['요일', '기상상태', '노면상태', '사고유형', '연', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t12 features in original data used to generate 12 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.8 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2399.15s of the 3599.62s of remaining time.\n",
      "\t0.3936\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2395.15s of the 3595.62s of remaining time.\n",
      "\t0.3727\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2394.27s of the 3594.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4736\t = Validation score   (accuracy)\n",
      "\t147.66s\t = Training   runtime\n",
      "\t1.38s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2220.45s of the 3420.92s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=90666, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 451, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90666, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 74, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/common/utils/try_import.py\", line 133, in try_import_lightgbm\n",
      "    raise ImportError(\"`import lightgbm` failed. If you are using Mac OSX, \" \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2212.78s of the 3413.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-11-17 00:34:05,374\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,378\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,380\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,383\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,395\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:05,400\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=90694, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 451, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=90694, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 74, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/common/utils/try_import.py\", line 133, in try_import_lightgbm\n",
      "    raise ImportError(\"`import lightgbm` failed. If you are using Mac OSX, \" \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2204.46s of the 3404.93s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.202 GB available memory (114.066%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L1... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2204.43s of the 3404.9s of remaining time.\n",
      "2023-11-17 00:34:08,378\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,384\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,387\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,390\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,397\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,400\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:34:08,404\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.199 GB available memory (114.361%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2204.36s of the 3404.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4736\t = Validation score   (accuracy)\n",
      "\t197.99s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1999.09s of the 3199.56s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.223 GB available memory (112.113%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.17 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L1... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1999.07s of the 3199.54s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.223 GB available memory (112.119%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.17 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1999.04s of the 3199.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4733\t = Validation score   (accuracy)\n",
      "\t40.6s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1951.32s of the 3151.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4737\t = Validation score   (accuracy)\n",
      "\t143.23s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1803.0s of the 3003.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=91085, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 451, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::_ray_fit()\u001b[39m (pid=91085, ip=127.0.0.1)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 829, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 74, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/autogluon/common/utils/try_import.py\", line 133, in try_import_lightgbm\n",
      "    raise ImportError(\"`import lightgbm` failed. If you are using Mac OSX, \" \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1797.05s of the 2997.52s of remaining time.\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "2023-11-17 00:41:01,281\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,284\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,286\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,291\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,295\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,300\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-17 00:41:01,304\tERROR worker.py:399 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.4734\t = Validation score   (accuracy)\n",
      "\t299.77s\t = Training   runtime\n",
      "\t2.66s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1637.91s of the 2838.38s of remaining time.\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4735\t = Validation score   (accuracy)\n",
      "\t1301.09s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 528.02s of the 1728.49s of remaining time.\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.473\t = Validation score   (accuracy)\n",
      "\t56.67s\t = Training   runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 508.65s of the 1709.12s of remaining time.\n",
      "\tFitting 8 child models (S2F1 - S2F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4732\t = Validation score   (accuracy)\n",
      "\t225.7s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Completed 2/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1623.66s of remaining time.\n",
      "\t0.4738\t = Validation score   (accuracy)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1618.42s of the 1618.35s of remaining time.\n",
      "\tMemory not enough to fit NNFastAiTabularModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 14)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 638.21s of the 638.15s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 637.61s of the 637.55s of remaining time.\n",
      "\tMemory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: <D21A7969-4567-3BC7-94ED-6A9E83AE9D78> /Users/itaeyun/opt/anaconda3/envs/dev/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file, not in dyld cache)\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 637.09s of the 637.03s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.088 GB available memory (126.036%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.31 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestGini_BAG_L2... Skipping this model.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 636.83s of the 636.76s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.686 GB out of 1.113 GB available memory (123.190%)... (50.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train RandomForestEntr_BAG_L2... Skipping this model.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 636.56s of the 636.5s of remaining time.\n",
      "\tMemory not enough to fit CatBoostModel folds in parallel. Will do sequential fitting instead. \tConsider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 73.\n",
      "\tTime limit exceeded... Skipping CatBoost_BAG_L2.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "No base models to train on, skipping auxiliary stack level 3...\n",
      "AutoGluon training complete, total runtime = 3902.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231116_153053/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "# # autogluon 학습을 위한 데이터 형태로 변환\n",
    "# train = TabularDataset(train_x.drop(['ID'], axis=1))\n",
    "# test = TabularDataset(test_x.drop(['ID'], axis=1))\n",
    "\n",
    "# 타겟 변수를 데이터 프레임에 추가\n",
    "train_x['ECLO'] = train_y\n",
    "\n",
    "# AutoGluon 학습을 위한 데이터 형태로 변환\n",
    "train_data = TabularDataset(data=train_x)\n",
    "\n",
    "predictor = TabularPredictor(label='ECLO').fit(\n",
    "    train_data=train_data, \n",
    "    presets='best_quality', \n",
    "    time_limit=60*60\n",
    ")\n",
    "\n",
    "# 예측하기\n",
    "pred_y = predictor.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ECLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCIDENT_39609</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCIDENT_39610</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACCIDENT_39611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCIDENT_39612</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACCIDENT_39613</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>ACCIDENT_50567</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>ACCIDENT_50568</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>ACCIDENT_50569</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>ACCIDENT_50570</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>ACCIDENT_50571</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10963 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  ECLO\n",
       "0      ACCIDENT_39609     3\n",
       "1      ACCIDENT_39610     3\n",
       "2      ACCIDENT_39611     3\n",
       "3      ACCIDENT_39612     3\n",
       "4      ACCIDENT_39613     3\n",
       "...               ...   ...\n",
       "10958  ACCIDENT_50567     3\n",
       "10959  ACCIDENT_50568     3\n",
       "10960  ACCIDENT_50569     3\n",
       "10961  ACCIDENT_50570     3\n",
       "10962  ACCIDENT_50571     3\n",
       "\n",
       "[10963 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "baseline_submission = sample_submission.copy()\n",
    "baseline_submission['ECLO'] = pred_y\n",
    "baseline_submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_submission.to_csv('second_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "329e22198b68d8e60cd009d73b7185815e21aa24b6d9ff67db9978dd5b8ddb29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
